{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=top></a>\n",
    "# DEV: Archetype Classification\n",
    "\n",
    "This notebook served the purpose of testing and hyperparameter optimization for morphological archetype classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import modules\n",
    "\n",
    "# External, general\n",
    "from __future__ import division\n",
    "import os, sys, pickle, warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# External, specific\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import sklearn.svm as svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Internal\n",
    "import katachi.utilities.loading as ld\n",
    "import katachi.utilities.atlas_helpers as atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Settings\n",
    "\n",
    "# Specify data source\n",
    "target_dir = r'data/experimentA/extracted_measurements/'\n",
    "fspace_type = \"TFOR\"\n",
    "#fspace_type = \"CFOR\"\n",
    "\n",
    "# Cross validation\n",
    "num_CVs = 5\n",
    "\n",
    "# Archetype annotation\n",
    "celltype_decodedict = {0 : 'unclassified',\n",
    "                       1 : 'innerRosetteCells',\n",
    "                       2 : 'outerRosetteCells',\n",
    "                       3 : 'betweenRosetteCells',\n",
    "                       4 : 'leaderCells'}\n",
    "celltype_encodedict = {name:key for key,name in celltype_decodedict.iteritems()}\n",
    "\n",
    "# Visualization options\n",
    "cellcolors = {0 : 'lightgray',\n",
    "              1 : 'royalblue',\n",
    "              2 : 'limegreen',\n",
    "              3 : 'cyan',\n",
    "              4 : 'orangered'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load data\n",
    "\n",
    "# Prep loader\n",
    "loader = ld.DataLoaderIDR(target_dir, recurse=True, verbose=True)\n",
    "\n",
    "# Load manual archetype annotations\n",
    "archetypes, prim_IDs, fspace_idx = loader.load_dataset(\"_archetype_manual_annotations.tsv\")\n",
    "print \"Imported manual archetype annotations of shape:\", archetypes.shape\n",
    "\n",
    "# Load corresponding feature spaces\n",
    "fspace = loader.load_dataset(\"_shape_\"+fspace_type+\"_raw_measured.tsv\", IDs=prim_IDs)[0]\n",
    "print \"Imported feature space of shape:\", fspace.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove cells that are not annotated\n",
    "\n",
    "# Select\n",
    "fspace     = fspace[~np.isnan(archetypes), :]\n",
    "archetypes = archetypes[~np.isnan(archetypes)]\n",
    "\n",
    "# Report\n",
    "print \"Reduced fspace to shape:    \", fspace.shape\n",
    "print \"Reduced archetypes to shape: \", archetypes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prep for cross-validation\n",
    "\n",
    "# Shuffle split for CV\n",
    "cv_sets = model_selection.StratifiedShuffleSplit(n_splits=num_CVs, test_size=0.3, random_state=42)\n",
    "\n",
    "# Prepare CV scorers\n",
    "scoring = {'accuracy'    : 'accuracy',\n",
    "           'f1_macro'    : 'f1_macro',\n",
    "           'f1_micro'    : 'f1_micro',\n",
    "           'f1_weighted' : 'f1_weighted'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build pipeline from preprocessing and regression\n",
    "\n",
    "# Prep pipeline\n",
    "pip = []\n",
    "\n",
    "# Preprocessing\n",
    "pip.append( ('Standardize', StandardScaler()) )\n",
    "pip.append( ('PCA', PCA()) )\n",
    "pip.append( ('Restandardize', StandardScaler()) )\n",
    "    \n",
    "# Regressor\n",
    "svc = svm.SVC(probability=True, kernel='rbf')\n",
    "pip.append( ('SVC', svc) )\n",
    "\n",
    "# Pipeline\n",
    "pip = Pipeline(pip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Perform hyperparameter optimization\n",
    "    \n",
    "# Param grid\n",
    "gd = 1.0 / fspace.shape[1]\n",
    "param_grid = [ {'Standardize'   : [None, StandardScaler()],\n",
    "                'PCA'           : [None, PCA(15), PCA(30), PCA(50)],\n",
    "                'Restandardize' : [None, StandardScaler()],\n",
    "                'SVC__C'        : [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "                'SVC__gamma'    : [gd*100.0, gd*10.0, gd*1.0, gd*0.1, gd*0.01]} ]\n",
    "\n",
    "# Run grid search\n",
    "clf = model_selection.GridSearchCV(pip, param_grid, cv=cv_sets, n_jobs=num_CVs, verbose=2)\n",
    "clf.fit(fspace, archetypes)\n",
    "\n",
    "# Available outputs\n",
    "print \"\\nOutputs:\"\n",
    "print sorted(clf.cv_results_.keys())\n",
    "\n",
    "# Key results\n",
    "print \"\\nResults:\"\n",
    "print clf.best_estimator_\n",
    "print clf.best_score_\n",
    "\n",
    "# Use best estimator\n",
    "best = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Perform cross-validation on best predictor\n",
    "\n",
    "# Run CV\n",
    "print \"Performing cross-validation...\"\n",
    "scores = model_selection.cross_validate(best, fspace, archetypes, cv=cv_sets, \n",
    "                                        scoring=scoring, return_train_score=True, \n",
    "                                        n_jobs=num_CVs)\n",
    "\n",
    "# Report scores\n",
    "atlas.report_cv_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create confusion matrix\n",
    "\n",
    "# Axis renaming for publication\n",
    "publ_rename_dict = {'innerRosetteCells' : 'central',\n",
    "                    'outerRosetteCells' : 'peri',\n",
    "                    'betweenRosetteCells' : 'inter',\n",
    "                    'leaderCells' : 'leader'}\n",
    "\n",
    "# Grab a specific train-test split\n",
    "split_indices = list(cv_sets.split(fspace, archetypes))[0]\n",
    "fspace_train, archetypes_train = fspace[split_indices[0], :], archetypes[split_indices[0]]\n",
    "fspace_test,  archetypes_test  = fspace[split_indices[1], :], archetypes[split_indices[1]]\n",
    "\n",
    "# Fit and predict\n",
    "best.fit(fspace_train, archetypes_train)\n",
    "archetypes_train_pred = best.predict(fspace_train)\n",
    "archetypes_test_pred  = best.predict(fspace_test)\n",
    "\n",
    "# Compute confusion matrices\n",
    "cm_train = metrics.confusion_matrix(archetypes_train, archetypes_train_pred)\n",
    "cm_test  = metrics.confusion_matrix(archetypes_test, archetypes_test_pred)\n",
    "\n",
    "# Prep plot\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8,8), sharey=True)\n",
    "\n",
    "# Function for creating and styling a confusion matrix\n",
    "def confmat(ax, cm):\n",
    "    \n",
    "    # Handle axis boundaries...\n",
    "    ax.set_adjustable('box-forced')\n",
    "    \n",
    "    # Show image and text\n",
    "    ax.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "    for (i, j), z in np.ndenumerate(cm):\n",
    "        ax.text(j, i, z, ha='center', va='center', fontsize=15)\n",
    "    \n",
    "    # Adjust ticks\n",
    "    ax.set_xticks(range(cm.shape[0]))\n",
    "    ax.set_yticks(range(cm.shape[0]))\n",
    "\n",
    "# Plot cm_train\n",
    "confmat(ax[0], cm_train)\n",
    "ax[0].set_title(fspace_type+\" train (n=%i)\" % fspace_train.shape[0], fontsize=17, y=1.02)\n",
    "ax[0].set_yticklabels([publ_rename_dict[celltype_decodedict[i]] for i in best.classes_], \n",
    "                      rotation=45, va='top', fontsize=14)\n",
    "ax[0].set_xticklabels([publ_rename_dict[celltype_decodedict[i]] for i in best.classes_], \n",
    "                      rotation=45, ha='right', fontsize=14)\n",
    "\n",
    "# Plot cm_test\n",
    "confmat(ax[1], cm_test)\n",
    "ax[1].set_title(fspace_type+\" test (n=%i)\" % fspace_test.shape[0], fontsize=17, y=1.02)\n",
    "ax[1].set_yticklabels([publ_rename_dict[celltype_decodedict[i]] for i in best.classes_], \n",
    "                      rotation=45, va='top', fontsize=14)\n",
    "ax[1].set_xticklabels([publ_rename_dict[celltype_decodedict[i]] for i in best.classes_], \n",
    "                      rotation=45, ha='right', fontsize=14)\n",
    "\n",
    "# Labels\n",
    "fig.text( 0.545, 0.19, 'prediction',   ha='center', va='center', fontsize=16)\n",
    "fig.text(-0.01, 0.50, 'ground truth', ha='center', va='center', rotation='vertical', fontsize=16)\n",
    "\n",
    "# Layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Done\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create probability embedding\n",
    "\n",
    "# Predict probabilities\n",
    "print \"\\nPredicting probabilities...\"\n",
    "archetypes_proba = best.predict_proba(fspace)\n",
    "print \"  Predicted archetypes_proba of shape:\", archetypes_proba.shape\n",
    "\n",
    "# PCA of probabilities\n",
    "print \"\\nEmbedding probabilities...\"\n",
    "embedPCA = PCA()\n",
    "proba_embedding = embedPCA.fit_transform(archetypes_proba)\n",
    "#proba_embedding = proba_embedding[:, embedPCA.explained_variance_ratio_ > 0.05]\n",
    "print \"  Expl. var. ratios:\", embedPCA.explained_variance_ratio_\n",
    "print \"  Created embedding of shape:  \", proba_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot archetype space in 2D\n",
    "\n",
    "# Prep plot\n",
    "plt.figure(figsize=(6,5))\n",
    "\n",
    "# Create scatter\n",
    "for key in celltype_decodedict.keys():\n",
    "    mask = archetypes==key\n",
    "    if np.any(mask):\n",
    "        scat = plt.scatter(proba_embedding[mask, 0], proba_embedding[mask, 1],\n",
    "                           color=cellcolors[key], edgecolor='', \n",
    "                           s=10, alpha=0.85, label=celltype_decodedict[key])\n",
    "    \n",
    "# Cosmetics  \n",
    "plt.legend(frameon=False, fontsize=8)\n",
    "plt.xlabel(\"PC 0\")\n",
    "plt.ylabel(\"PC 1\")\n",
    "plt.title(\"archetype classification probability embedding\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot archetype space in 3D\n",
    "\n",
    "# Prep plot\n",
    "fig = plt.figure(figsize=(9,7))\n",
    "ax  = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Create scatter\n",
    "for key in celltype_decodedict.keys():\n",
    "    mask = archetypes==key\n",
    "    if np.any(mask):\n",
    "        ax.scatter(proba_embedding[mask, 0], \n",
    "                   proba_embedding[mask, 1], \n",
    "                   proba_embedding[mask, 2],\n",
    "                   c=cellcolors[key], edgecolor='face', \n",
    "                   s=10, alpha=0.85, label=celltype_decodedict[key])\n",
    "\n",
    "# Switch off gray panes\n",
    "ax.w_xaxis.set_pane_color((1.0, 1.0, 1.0, 1.0))\n",
    "ax.w_yaxis.set_pane_color((1.0, 1.0, 1.0, 1.0))\n",
    "ax.w_zaxis.set_pane_color((1.0, 1.0, 1.0, 1.0))\n",
    "        \n",
    "# Cosmetics  \n",
    "ax.legend(frameon=False, fontsize=8)\n",
    "ax.set_xlabel(\"PC 0\")\n",
    "ax.set_ylabel(\"PC 1\")\n",
    "ax.set_zlabel(\"PC 2\")\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "[Back to Top](#top)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
