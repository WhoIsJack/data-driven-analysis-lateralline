{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=top></a>\n",
    "# Pea3 smFISH Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "----\n",
    "\n",
    "1. [Preparations](#prep)\n",
    "2. [QC: Spot Detection](#QC_spots)\n",
    "3. [QC: Cell Shape](#QC_shape)\n",
    "4. [Data Visualization](#viz)\n",
    "5. [Predicting Expression from Shape: Testing](#atlas_test)\n",
    "6. [Predicting Expression from Shape: Running](#atlas_run)\n",
    "7. [Predicting Expression from Shape: Visualization](#atlas_viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=prep></a>\n",
    "\n",
    "## 1. Preparations\n",
    "[back to top](#top)\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import modules\n",
    "\n",
    "# External, general\n",
    "from __future__ import division\n",
    "import os, sys, pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# External, specific\n",
    "import ipywidgets as widgets\n",
    "import scipy.stats as stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage import io\n",
    "from sklearn import model_selection, metrics, multioutput\n",
    "import sklearn.svm as svm\n",
    "\n",
    "# Internal\n",
    "import katachi.utilities.loading as ld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load general data\n",
    "\n",
    "# Prep loader\n",
    "loader = ld.DataLoaderIDR()\n",
    "loader.find_imports(r\"data/experimentB/extracted_measurements/\", recurse=True, verbose=True)\n",
    "\n",
    "# Import shape spaces\n",
    "fspace_TFOR, prim_IDs, fspace_idx = loader.load_dataset(\"shape_TFOR_raw_measured.tsv\")\n",
    "fspace_CFOR, _, _ = loader.load_dataset(\"shape_CFOR_raw_measured.tsv\", IDs=prim_IDs)\n",
    "print \"Imported TFOR shape space of shape:\", fspace_TFOR.shape\n",
    "print \"Imported CFOR shape space of shape:\", fspace_CFOR.shape\n",
    "\n",
    "# Standardization and PCA\n",
    "fspace_TFOR_z = StandardScaler().fit_transform(fspace_TFOR)\n",
    "pca_TFOR = PCA()\n",
    "fspace_TFOR_pca = pca_TFOR.fit_transform(fspace_TFOR_z)\n",
    "fspace_CFOR_z = StandardScaler().fit_transform(fspace_CFOR)\n",
    "pca_CFOR = PCA()\n",
    "fspace_CFOR_pca = pca_CFOR.fit_transform(fspace_CFOR_z)\n",
    "\n",
    "# Import TFOR centroid locations\n",
    "centroids = loader.load_dataset(\"_other_measurements.tsv\", IDs=prim_IDs)[0][:,3:6][:,::-1]\n",
    "print \"Imported TFOR centroids of shape:\", centroids.shape\n",
    "\n",
    "# Import & standardize engineered features\n",
    "covar_df, _, _ = loader.load_dataset(\"_other_measurements.tsv\", IDs=prim_IDs, force_df=True)\n",
    "del covar_df['Centroids RAW X']; del covar_df['Centroids RAW Y']; del covar_df['Centroids RAW Z']\n",
    "covar_names = list(covar_df.columns)\n",
    "covar_df_z = (covar_df - covar_df.mean()) / covar_df.std()\n",
    "print \"Imported engineered features of shape:\", covar_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load smFISH data\n",
    "\n",
    "# Counts\n",
    "rna_counts, _, _ = loader.load_dataset(\"pea3smFISH_RNAcounts_measured.tsv\", IDs=prim_IDs)\n",
    "print \"Imported RNA counts data of shape:\", rna_counts.shape\n",
    "\n",
    "# Spots\n",
    "rna_spots, _, _= loader.load_dataset(\"pea3smFISH_RNAspot_coordinates.tsv\", IDs=prim_IDs, force_dict=True)\n",
    "print \"Imported RNA spot coordinates for\", len(rna_spots), \"samples, the first having shape\", rna_spots[prim_IDs[0]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Outlier removal\n",
    "\n",
    "# Remove samples with `mean(rna_counts) <= mean_count_thresh` as a simple and helpful quality threshold\n",
    "mean_count_thresh = 2\n",
    "count_means = [np.mean(rna_counts[fspace_idx==prim_idx]) for prim_idx in range(len(prim_IDs))]\n",
    "rna_exclude_prim_mask = np.array(count_means) > mean_count_thresh\n",
    "rna_exclude_cell_mask = rna_exclude_prim_mask[fspace_idx]\n",
    "\n",
    "# Report\n",
    "print \"Excluding\", np.sum(~rna_exclude_prim_mask), \"prims /\", np.sum(~rna_exclude_cell_mask), \"cells,\",\n",
    "print \"resulting in\", np.sum(rna_exclude_prim_mask), \"prims /\", np.sum(rna_exclude_cell_mask), \"cells\",\n",
    "print \"left for analysis.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=QC_spots></a>\n",
    "\n",
    "## 2. QC: Spot Detection\n",
    "[back to top](#top)\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Boxplot of mean counts & per-cell counts\n",
    "\n",
    "# Note: \n",
    "#  - Durdu et al. found a mean of ~11 spots/cell in their manually analyzed data.\n",
    "#    This plot is designed to fit their way of reporting the results.\n",
    "#  - This is recapitulated quite well here, except for a couple of outliers with \n",
    "#    unrealistically low expression.\n",
    "#  - However, note that the cell-level distribution is very non-normal, so the mean \n",
    "#    is not a very good summary characteristic.\n",
    "\n",
    "# Get count means\n",
    "count_means = np.array([np.mean(rna_counts[fspace_idx==prim_idx]) \n",
    "                        for prim_idx in range(len(prim_IDs))])\n",
    "\n",
    "# Fig prep\n",
    "fig, ax = plt.subplots(1, 2, figsize=(3.5, 4.5))\n",
    "\n",
    "# Make boxplots\n",
    "bp_m = ax[0].boxplot(count_means, widths=0.5, patch_artist=True)\n",
    "bp_a = ax[1].boxplot(rna_counts, widths=0.5, patch_artist=True, showfliers=False)\n",
    "\n",
    "# Boxplot styling function (making it similar to Sevi's paper)\n",
    "def style_boxplot(bp):\n",
    "    for patch in bp['boxes']:\n",
    "        patch.set(edgecolor='black', linewidth=1.2,)\n",
    "    for whisker in bp['whiskers']:\n",
    "        whisker.set(color='black', linestyle='-')\n",
    "    for cap in bp['caps']:\n",
    "        cap.set(linewidth=1.2)\n",
    "    for median in bp['medians']:\n",
    "        median.set(color='black', linewidth=1.2)\n",
    "        \n",
    "# Style the boxplots\n",
    "style_boxplot(bp_m)\n",
    "style_boxplot(bp_a)\n",
    "\n",
    "# Add scatter\n",
    "ax[0].scatter(np.random.normal(1.0, 0.06, len(count_means)), count_means, \n",
    "              zorder=10, s=20, alpha=0.7, c='midnightblue', edgecolor='')\n",
    "ax[0].set_ylim([-2, 47])\n",
    "ax[1].scatter(np.random.normal(1.0, 0.06, len(rna_counts)), rna_counts, \n",
    "              zorder=10, s=2, alpha=0.1, c='midnightblue', edgecolor='')\n",
    "ax[1].set_ylim([-2, 100])\n",
    "\n",
    "# Remove ticks\n",
    "ax[0].yaxis.set_ticks_position('left')\n",
    "ax[0].xaxis.set_ticks_position('bottom')\n",
    "ax[1].yaxis.set_ticks_position('left')\n",
    "ax[1].xaxis.set_ticks_position('bottom')\n",
    "\n",
    "# Axis labels\n",
    "from matplotlib import rcParams\n",
    "rcParams['mathtext.default'] = 'regular'\n",
    "ax[0].set_ylabel(r'$\\it{pea3}$ transcripts per cell (mean)', fontsize=12, labelpad=5)\n",
    "ax[0].set_xticklabels(['WT 880'], rotation=90, fontsize=12)\n",
    "ax[1].set_ylabel(r'$\\it{pea3}$ transcripts per cell (all)', fontsize=12, labelpad=0)\n",
    "ax[1].set_xticklabels(['WT 880'], rotation=90, fontsize=12)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Histograms of RNA counts for each sample\n",
    "\n",
    "# Prep\n",
    "n_plot_cols = 7\n",
    "n_plot_rows = int(np.ceil(len(prim_IDs) / n_plot_cols))\n",
    "fig, ax = plt.subplots(n_plot_rows, n_plot_cols, figsize=(1.5*n_plot_cols, 1.5*n_plot_rows),\n",
    "                       sharex=True, sharey=True)\n",
    "ax = ax.flatten()\n",
    "[ax[i].axis('off') for i in range(len(prim_IDs), n_plot_cols*n_plot_rows)]\n",
    "\n",
    "# For each sample...\n",
    "for axx, prim_idx, prim_ID, is_outlier in zip(ax, range(len(prim_IDs)), prim_IDs, ~rna_exclude_prim_mask):\n",
    "    \n",
    "    # Generate the histogram\n",
    "    axx.hist(rna_counts[fspace_idx==prim_idx], \n",
    "             bins=40, range=(rna_counts.min(), rna_counts.max()),\n",
    "             histtype='stepfilled', color='darkblue' if not is_outlier else 'darkred', alpha=0.5)\n",
    "    axx.set_title(prim_ID, fontsize=9)\n",
    "\n",
    "# Set common axis labels\n",
    "fig.text(0.5, -0.01, 'RNA Counts', ha='center', va='center')\n",
    "fig.text(-0.01, 0.50, 'Histogram\\nof Cells',  ha='center', va='center', rotation='vertical')\n",
    "\n",
    "# Done\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Histogram of counts over all cells\n",
    "\n",
    "# Prep\n",
    "plt.figure(figsize=(5, 3))\n",
    "\n",
    "# Make hist\n",
    "plt.hist(rna_counts, bins=100, histtype='stepfilled', color='b', alpha=0.5)\n",
    "\n",
    "# Label\n",
    "plt.xlabel('RNA Count')\n",
    "plt.ylabel('Histogram of Cells')\n",
    "\n",
    "# Done\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=QC_shape></a>\n",
    "\n",
    "## 3. QC: Cell Shape (Fixation Effects)\n",
    "[back to top](#top)\n",
    "\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load live imaging reference data\n",
    "\n",
    "# Prep loader\n",
    "ref_loader = ld.DataLoaderIDR()\n",
    "ref_loader.find_imports(r\"data/experimentA/extracted_measurements/\", recurse=True, verbose=True)\n",
    "\n",
    "# Use only the 24 samples that were single-color imaged\n",
    "ref_IDs = ['056F63395C', '08B96BE794', '0B51F8B46C', '1C43D83E9A', '2902E38204', '4DC24FC301',  \n",
    "           '6F18162F4C', '8C633380D2', 'B95A4F6D95', 'CB87D7CBC9', '0E48AB134C', '3612A6CEF5', \n",
    "           '8713481504', '8C83D4387F', 'AB98466077', 'C95F528559', 'E013272A99', 'E6E56C3F42', \n",
    "           '22DF2AE1A0', '2B23352582', '673A65D087', '8CA33561B5', 'EC77708A51', 'FC90367714']\n",
    "\n",
    "# Import shape spaces\n",
    "ref_TFOR, _, ref_idx = ref_loader.load_dataset(\"shape_TFOR_raw_measured.tsv\", IDs=ref_IDs)\n",
    "ref_CFOR, _, _ = ref_loader.load_dataset(\"shape_CFOR_raw_measured.tsv\", IDs=ref_IDs)\n",
    "print \"Imported TFOR shape space of shape:\", ref_TFOR.shape\n",
    "print \"Imported CFOR shape space of shape:\", ref_CFOR.shape\n",
    "\n",
    "# Standardization and apply PCA (fitted above)\n",
    "ref_TFOR_z = StandardScaler().fit_transform(ref_TFOR)\n",
    "ref_TFOR_pca = pca_TFOR.transform(ref_TFOR_z)\n",
    "ref_CFOR_z = StandardScaler().fit_transform(ref_CFOR)\n",
    "ref_CFOR_pca = pca_CFOR.transform(ref_CFOR_z)\n",
    "\n",
    "# Import & standardize engineered features\n",
    "ref_covar_df, _, _ = ref_loader.load_dataset(\"_other_measurements.tsv\", IDs=ref_IDs, force_df=True)\n",
    "del ref_covar_df['Centroids RAW X']; del ref_covar_df['Centroids RAW Y']; del ref_covar_df['Centroids RAW Z']\n",
    "ref_covar_names = list(ref_covar_df.columns)\n",
    "ref_covar_df_z = (ref_covar_df - ref_covar_df.mean()) / ref_covar_df.std()\n",
    "print \"Imported engineered features of shape:\", ref_covar_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compare to reference shape spaces: overlay\n",
    "\n",
    "# Set interactions\n",
    "@widgets.interact(PCx=(1, fspace_TFOR_pca.shape[1], 1),\n",
    "                  PCy=(1, fspace_TFOR_pca.shape[1], 1))\n",
    "\n",
    "# Show \n",
    "def show_PCs(PCx=1, PCy=2): \n",
    "    \n",
    "    # Prep\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12,5))\n",
    "        \n",
    "    # Plot TFOR\n",
    "    ax[0].scatter(ref_TFOR_pca[:,PCx-1], ref_TFOR_pca[:,PCy-1],\n",
    "                c='b', cmap=plt.cm.plasma, edgecolor='', \n",
    "                s=20, alpha=0.25, label='reference')\n",
    "    ax[0].scatter(fspace_TFOR_pca[:,PCx-1], fspace_TFOR_pca[:,PCy-1],\n",
    "                c='r', cmap=plt.cm.plasma, edgecolor='',\n",
    "                s=20, alpha=0.25, label='fixed')\n",
    "    \n",
    "    # Plot CFOR\n",
    "    ax[1].scatter(ref_CFOR_pca[:,PCx-1], ref_CFOR_pca[:,PCy-1],\n",
    "                c='b', cmap=plt.cm.plasma, edgecolor='', \n",
    "                s=20, alpha=0.25, label='reference')\n",
    "    ax[1].scatter(fspace_CFOR_pca[:,PCx-1], fspace_CFOR_pca[:,PCy-1],\n",
    "                c='r', cmap=plt.cm.plasma, edgecolor='',\n",
    "                s=20, alpha=0.25, label='fixed')\n",
    "\n",
    "    # Cosmetics\n",
    "    ax[0].legend(fontsize=8, frameon=False)\n",
    "    ax[0].set_xlabel(\"PC \"+str(PCx))\n",
    "    ax[1].set_xlabel(\"PC \"+str(PCx))\n",
    "    ax[0].set_ylabel(\"PC \"+str(PCy))\n",
    "    ax[1].set_ylabel(\"PC \"+str(PCy))\n",
    "    ax[0].set_title(\"TFOR\")\n",
    "    ax[1].set_title(\"CFOR\")\n",
    "    \n",
    "    # Done\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compare to reference cell extents\n",
    "\n",
    "# Prep for plots\n",
    "fig, ax = plt.subplots(1, 3, figsize=(6.5,3), sharey=True)\n",
    "\n",
    "# Create plots\n",
    "for i, lbl in enumerate(['Z', 'Y', 'X']):\n",
    "\n",
    "    # Violinplot\n",
    "    vio = ax[i].violinplot([ref_covar_df[lbl+' Axis Length'], \n",
    "                            covar_df[lbl+' Axis Length']], \n",
    "                           widths=0.60, showextrema=False)\n",
    "\n",
    "    # Violinplot cosmetics\n",
    "    vio['bodies'][0].set_facecolors('lightskyblue')\n",
    "    vio['bodies'][1].set_facecolors('tomato')\n",
    "    ax[i].set_xlim(0.3, 2.7)\n",
    "    ax[i].set_xticks([1.0, 2.0])\n",
    "    ax[i].set_xticklabels([\"Reference\", \"Fixed\"])\n",
    "    ax[i].set_ylabel(lbl)\n",
    "\n",
    "    # Jitter\n",
    "    for j,y in enumerate([ref_covar_df[lbl+' Axis Length'], covar_df[lbl+' Axis Length']]):\n",
    "        x = np.random.normal(j+1, 0.08, size=len(y))\n",
    "        ax[i].plot(x, y, '.', color=['blue', 'red'][j], alpha=[0.1, 0.1][j], ms=2)\n",
    "\n",
    "# Done\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compare to reference cell sphericity\n",
    "\n",
    "# Violinplot\n",
    "plt.figure(figsize=(2,3))\n",
    "vio = plt.violinplot([ref_covar_df['Sphericity'], covar_df['Sphericity']], \n",
    "                     widths=0.60, showextrema=False)\n",
    "\n",
    "# Violinplot cosmetics\n",
    "vio['bodies'][0].set_facecolors('lightskyblue')\n",
    "vio['bodies'][1].set_facecolors('tomato')\n",
    "plt.xlim(0.3, 2.7)\n",
    "plt.xticks([1.0, 2.0])\n",
    "plt.gca().set_xticklabels([\"Reference\", \"Fixed\"])\n",
    "plt.ylabel(\"Cell Sphericity\")\n",
    "\n",
    "# Jitter\n",
    "for i,y in enumerate([ref_covar_df['Sphericity'], covar_df['Sphericity']]):\n",
    "    x = np.random.normal(i+1, 0.08, size=len(y))\n",
    "    plt.plot(x, y, '.', color=['blue', 'red'][i], alpha=[0.1, 0.1][i], ms=2)\n",
    "\n",
    "# Done\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compare to reference cell volume\n",
    "\n",
    "# Violinplot\n",
    "plt.figure(figsize=(2,3))\n",
    "vio = plt.violinplot([ref_covar_df['Volume'], covar_df['Volume']], widths=0.60, showextrema=False)\n",
    "\n",
    "# Violinplot cosmetics\n",
    "vio['bodies'][0].set_facecolors('lightskyblue')\n",
    "vio['bodies'][1].set_facecolors('tomato')\n",
    "plt.xlim(0.3, 2.7)\n",
    "plt.xticks([1.0, 2.0])\n",
    "plt.gca().set_xticklabels([\"Reference\", \"Fixed\"])\n",
    "plt.ylabel(\"Cell Volume\")\n",
    "\n",
    "# Jitter\n",
    "for i,y in enumerate([ref_covar_df['Volume'], covar_df['Volume']]):\n",
    "    x = np.random.normal(i+1, 0.08, size=len(y))\n",
    "    plt.plot(x, y, '.', color=['blue', 'red'][i], alpha=[0.1, 0.1][i], ms=2)\n",
    "\n",
    "# Done\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For publication: compare to diverse set of shape references\n",
    "\n",
    "# Prep for plots\n",
    "fig, ax = plt.subplots(1, 3, figsize=(8, 3.5))\n",
    "\n",
    "# Violinplot\n",
    "vio_data = [[ref_TFOR_pca[:,0], fspace_TFOR_pca[:,0]],  # TFOR PC 1\n",
    "            [ref_CFOR_pca[:,0], fspace_CFOR_pca[:,0]],  # CFOR PC 1\n",
    "            [ref_covar_df['Z Axis Length'], covar_df['Z Axis Length']]]  # Cell Height\n",
    "\n",
    "# Create plots\n",
    "for i, lbl in enumerate(['TFOR-PC1 (D-V orient.)', \n",
    "                         'CFOR-PC1 (sphericity)', \n",
    "                         r'Cell height $\\it{[\\mu m]}$']):\n",
    "\n",
    "    # Violinplot\n",
    "    vio = ax[i].violinplot(vio_data[i], widths=0.70, showextrema=False)\n",
    "\n",
    "    # Violinplot cosmetics\n",
    "    vio['bodies'][0].set_facecolors('w')\n",
    "    vio['bodies'][1].set_facecolors('w')\n",
    "    ax[i].set_xlim(0.3, 2.7)\n",
    "    ylims = ax[i].get_ylim()\n",
    "    ax[i].set_ylim(ylims[0]-(ylims[1]-ylims[0])*0.05, ylims[1]+(ylims[1]-ylims[0])*0.2)\n",
    "    ax[i].set_xticks([1.0, 2.0])\n",
    "    ax[i].set_xticklabels([\"Live\", \"Fixed\"], fontsize=14)\n",
    "    ax[i].set_ylabel(lbl, fontsize=14, labelpad=0)\n",
    "    ax[i].set_yticklabels([int(n) for n in ax[i].get_yticks()], fontsize=14)\n",
    "    \n",
    "    # Jitter\n",
    "    for j,y in enumerate(vio_data[i]):\n",
    "        x = np.random.normal(j+1, 0.08, size=len(y))\n",
    "        ax[i].plot(x, y, '.', color=['blue', 'midnightblue'][j], alpha=[0.1, 0.1][j], ms=2)\n",
    "        \n",
    "    # Print stats\n",
    "    print 'pMWU('+lbl+'):', stats.mannwhitneyu(*vio_data[i], alternative='two-sided')[1]\n",
    "\n",
    "# Cosmetics\n",
    "plt.tight_layout()\n",
    "\n",
    "# Done\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=viz></a>\n",
    "\n",
    "## 4. Data Visualization\n",
    "[back to top](#top)\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Overlay of detected spots on the images\n",
    "### Note: This takes quite a while to run and process everything!\n",
    "\n",
    "# Some extra info/settings\n",
    "img_data_dir = r'data/experimentB/image_data/'  # Image data directory\n",
    "res = [0.1867357, 0.0851964, 0.0851964]  # Image data resolution\n",
    "spot_viz_IDs = ['EF83427BD6', '5AFF045EBD', '4E2807EBE0']  # Image subset (visually the best)\n",
    "\n",
    "# Preload and precompute images\n",
    "smf_images = {}\n",
    "mem_images = {}\n",
    "seg_images = {}\n",
    "for prim_ID in spot_viz_IDs:\n",
    "    img_data_path = os.path.join(img_data_dir, prim_ID)\n",
    "    prim_idx = prim_IDs.index(prim_ID)\n",
    "\n",
    "    # Preload and zmax project the smFISH images\n",
    "    smf_img = io.imread(os.path.join(img_data_path, prim_ID+'_8bit_pea3smFISH.tif'))\n",
    "    smf_images[prim_ID] = smf_img.max(axis=0)\n",
    "\n",
    "    # Preload and zmax project the membrane images\n",
    "    mem_img = io.imread(os.path.join(img_data_path, prim_ID+'_8bit_lynEGFP.tif'))\n",
    "    mem_images[prim_ID] = mem_img.max(axis=0)\n",
    "\n",
    "    # Preload the segmentations and backmap the counts\n",
    "    seg_img = io.imread(os.path.join(img_data_path, prim_ID+'_8bit_lynEGFP_seg.tif'))\n",
    "    seg_img_counts = np.zeros_like(seg_img, dtype=np.int)\n",
    "    for cell_idx, cell_ID in enumerate(np.unique(seg_img)[1:]):\n",
    "        seg_img_counts[seg_img==cell_ID] = rna_counts[fspace_idx==prim_idx][cell_idx]\n",
    "    seg_images[prim_ID] = seg_img_counts.max(axis=0)\n",
    "\n",
    "# Interactive\n",
    "from ipywidgets import interact\n",
    "@interact(prim_ID=spot_viz_IDs,\n",
    "          show_dots=True,\n",
    "          show_seg=False,\n",
    "          show_mem=False,\n",
    "          zoomed=False)\n",
    "\n",
    "# Plot func\n",
    "def make_overlay(prim_ID=spot_viz_IDs[0], show_dots=True, show_seg=False, \n",
    "                 show_mem=False, zoomed=False):\n",
    "\n",
    "    # Handle weird str->unicode issue\n",
    "    prim_ID = str(prim_ID)\n",
    "\n",
    "    # Zooming to ROI (manual toggle)\n",
    "    roi_loc = (810, 400)\n",
    "    roi_size = (170, 170)\n",
    "\n",
    "    # Load and process the image data\n",
    "    if not show_seg and not show_mem:\n",
    "        img = smf_images[prim_ID]\n",
    "    if show_seg:\n",
    "        img = seg_images[prim_ID]\n",
    "    if show_mem:\n",
    "        img = mem_images[prim_ID]\n",
    "\n",
    "    # Prep\n",
    "    plt.figure(figsize=(12,5))\n",
    "\n",
    "    # Show projected img\n",
    "    plt.imshow(img, interpolation='none', \n",
    "               cmap='viridis' if show_seg else 'gray')\n",
    "\n",
    "    # Show identified dots\n",
    "    if show_dots:\n",
    "        if not zoomed:\n",
    "            plt.scatter(rna_spots[prim_ID][:,2], rna_spots[prim_ID][:,1], \n",
    "                        s=10, facecolors='', edgecolors='r', marker='o', linewidth=0.5,\n",
    "                        alpha=0.8 if show_seg else 0.5)\n",
    "        if zoomed:\n",
    "            plt.scatter(rna_spots[prim_ID][:,2], rna_spots[prim_ID][:,1], \n",
    "                        s=80, facecolors='', edgecolors='r', marker='o', linewidth=1.0,\n",
    "                        alpha=0.8 if show_seg else 0.7) \n",
    "\n",
    "    # Scale bar\n",
    "    scbar_start = img.shape[1] - img.shape[1]*0.1\n",
    "    scbar_yloc  = img.shape[0] - img.shape[0]*0.05\n",
    "    if not zoomed:\n",
    "        plt.plot([scbar_start, scbar_start+10/res[1]], \n",
    "                 [scbar_yloc, scbar_yloc], \n",
    "                 'w-', linewidth=6)\n",
    "    if zoomed:\n",
    "        plt.plot([roi_loc[0]+(3.1/4*roi_size[0]), \n",
    "                  roi_loc[0]+(3.1/4*roi_size[0])+2/res[1]], \n",
    "                 [roi_loc[1]+(9/10*roi_size[1]), roi_loc[1]+(9/10*roi_size[1])], \n",
    "                  'w-', linewidth=6) # For zoomed!\n",
    "\n",
    "    # Rectangle\n",
    "    if not zoomed:\n",
    "        import matplotlib.patches as patches\n",
    "        rect = patches.Rectangle(roi_loc,*roi_size, linewidth=2, \n",
    "                                 edgecolor='y', facecolor='none')\n",
    "        plt.gca().add_patch(rect)\n",
    "\n",
    "    # Cosmetics\n",
    "    plt.ylim(0, img.shape[0])\n",
    "    plt.xlim(0, img.shape[1])\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Zoom to rectangle\n",
    "    if zoomed:\n",
    "        plt.xlim(roi_loc[0], roi_loc[0]+roi_size[0])\n",
    "        plt.ylim(roi_loc[1], roi_loc[1]+roi_size[1])\n",
    "        plt.gca().invert_yaxis()\n",
    "\n",
    "    # Done\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Overlay of counts on shape spaces\n",
    "\n",
    "# Set interactions\n",
    "@widgets.interact(PCx=(1, fspace_TFOR_pca.shape[1], 1),\n",
    "                  PCy=(1, fspace_TFOR_pca.shape[1], 1),\n",
    "                  vmax_factor=(0.0, 1.0, 0.1))\n",
    "\n",
    "# Show \n",
    "def show_PCs(PCx=1, PCy=2, vmax_factor=0.5): \n",
    "    \n",
    "    # Prep\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12,5))\n",
    "        \n",
    "    # Plot TFOR\n",
    "    ax[0].scatter(fspace_TFOR_pca[:,PCx-1], fspace_TFOR_pca[:,PCy-1],\n",
    "                  c=rna_counts, cmap=plt.cm.plasma, \n",
    "                  vmax=vmax_factor*np.max(rna_counts),\n",
    "                  s=20, edgecolor='', alpha=0.5)\n",
    "    \n",
    "    # Plot CFOR\n",
    "    ax[1].scatter(fspace_CFOR_pca[:,PCx-1], fspace_CFOR_pca[:,PCy-1],\n",
    "                  c=rna_counts, cmap=plt.cm.plasma,\n",
    "                  vmax=vmax_factor*np.max(rna_counts),\n",
    "                  s=20, edgecolor='', alpha=0.5)\n",
    "\n",
    "    # Cosmetics \n",
    "    ax[0].set_xlabel(\"PC \"+str(PCx))\n",
    "    ax[1].set_xlabel(\"PC \"+str(PCx))\n",
    "    ax[0].set_ylabel(\"PC \"+str(PCy))\n",
    "    ax[1].set_ylabel(\"PC \"+str(PCy))\n",
    "    ax[0].set_title(\"TFOR\")\n",
    "    ax[1].set_title(\"CFOR\")\n",
    "    \n",
    "    # Done\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tissue consensus map\n",
    "\n",
    "# Note: This suffers a little because some prims are so weirdly angled in the images\n",
    "#       that the TFOR transform didn't get them quite right.\n",
    "\n",
    "# Settings\n",
    "xlim = (-130,  8)\n",
    "ylim = ( -19, 19)\n",
    "\n",
    "# Exclude weirdly TFOR-ed prims (those with centroids of `x > 0`) for cleaner visualization\n",
    "centroid_exclude_prim_mask = np.array([np.max(centroids[fspace_idx==prim_idx,-1]) \n",
    "                                      for prim_idx in range(len(prim_IDs))]) < 5\n",
    "centroid_exclude_cell_mask = centroid_exclude_prim_mask[fspace_idx]\n",
    "plot_exclude_cell_mask = rna_exclude_cell_mask & centroid_exclude_cell_mask\n",
    "\n",
    "# Get plot values & remove outliers\n",
    "plot_values = rna_counts[plot_exclude_cell_mask]\n",
    "\n",
    "# Tools for smoothing on scatter\n",
    "from katachi.utilities.pcl_helpers import pcl_gaussian_smooth\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# Cut off at prim contour outline\n",
    "kernel_prim = stats.gaussian_kde(centroids[plot_exclude_cell_mask,1:].T)\n",
    "f_prim = kernel_prim(centroids[plot_exclude_cell_mask,1:].T)\n",
    "f_prim_mask = f_prim > f_prim.min() + (f_prim.max()-f_prim.min())*0.1\n",
    "plot_values    = plot_values[f_prim_mask]\n",
    "plot_centroids = centroids[plot_exclude_cell_mask][f_prim_mask]\n",
    "\n",
    "# Smoothen?\n",
    "pdists = squareform(pdist(plot_centroids[:,1:]))\n",
    "plot_values = pcl_gaussian_smooth(pdists, plot_values[:,np.newaxis], sg_percentile=0.5)[:,0]\n",
    "\n",
    "# Initialize figure\n",
    "fig, ax = plt.subplots(1, figsize=(8, 2.8))\n",
    "\n",
    "# Contourf plot\n",
    "cfset = ax.tricontourf(plot_centroids[:,2], plot_centroids[:,1], plot_values, 20, \n",
    "                       cmap='plasma', vmax=20) # Note: vmax manually set for consistency across plots!\n",
    "\n",
    "# Illustrative centroids from a single prim\n",
    "plt.scatter(centroids[fspace_idx==prim_IDs.index(prim_IDs[12]), 2], \n",
    "            centroids[fspace_idx==prim_IDs.index(prim_IDs[12]), 1],\n",
    "            c='', alpha=0.5)\n",
    "\n",
    "# Cosmetics\n",
    "ax.set_xlabel('TFOR x', fontsize=16)\n",
    "ax.set_ylabel('TFOR y', fontsize=16)\n",
    "plt.tick_params(axis='both', which='major', labelsize=13)\n",
    "plt.xlim(xlim); plt.ylim(ylim)\n",
    "ax.invert_yaxis()  # To match images\n",
    "\n",
    "# Colorbar\n",
    "cbar = plt.colorbar(cfset, ax=ax, pad=0.01)\n",
    "cbar.set_label('RNA Counts', rotation=270, labelpad=15, fontsize=16)\n",
    "cbar.ax.tick_params(labelsize=13)\n",
    "\n",
    "# Finalize\n",
    "plt.tight_layout()\n",
    "\n",
    "# Done\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=atlas_test></a>\n",
    "\n",
    "## 5. Predicting Expression from Shape: Testing\n",
    "[back to top](#top)\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Settings, scoring & metrics\n",
    "\n",
    "# General\n",
    "use_PCs   = 10\n",
    "num_CVs   = 5\n",
    "test_size = 0.3\n",
    "\n",
    "# Shuffle split for CV\n",
    "cv_sets = model_selection.ShuffleSplit(n_splits=num_CVs, test_size=test_size, random_state=42)\n",
    "\n",
    "# Prepare CV scorers\n",
    "scoring = {'explained_variance'  : metrics.make_scorer(metrics.explained_variance_score),\n",
    "           'mean_squared_error'  : metrics.make_scorer(metrics.mean_squared_error),\n",
    "           'r2_score'            : metrics.make_scorer(metrics.r2_score)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Various prep of feature/target spaces\n",
    "\n",
    "# Prepare counts by adding 2nd dim\n",
    "rna_counts_rdy = np.expand_dims(rna_counts, -1)\n",
    "\n",
    "# Prepare location data by z-scoring\n",
    "centroids_z = StandardScaler().fit_transform(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove prims/cells that were excluded as outliers\n",
    "\n",
    "# Prepare fspaces & counts by removing excluded prims and subselecting PCs\n",
    "rna_counts_rdy      = rna_counts_rdy[rna_exclude_cell_mask]\n",
    "fspace_TFOR_pca_rdy = fspace_TFOR_pca[rna_exclude_cell_mask, :use_PCs]\n",
    "fspace_CFOR_pca_rdy = fspace_CFOR_pca[rna_exclude_cell_mask, :use_PCs]\n",
    "centroids_z_rdy     = centroids_z[rna_exclude_cell_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simple score reporting function\n",
    "\n",
    "def report_score(scores, score_key):\n",
    "    print \"%s: %.3f +/- %.3f\" % (score_key, np.mean(scores[score_key]), np.std(scores[score_key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting expression from TFOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare single train-test split for visualization\n",
    "\n",
    "# Split\n",
    "out = model_selection.train_test_split(fspace_TFOR_pca_rdy, rna_counts_rdy, \n",
    "                                       test_size=test_size, random_state=42)\n",
    "X_train, X_test, y_train, y_test = out\n",
    "\n",
    "# Report\n",
    "print \"Final source fspace (full, train, test):\", fspace_TFOR_pca_rdy.shape, X_train.shape, X_test.shape\n",
    "print \"Final target fspace (full, train, test):\", rna_counts_rdy.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter screening for SVR\n",
    "\n",
    "# Param grid\n",
    "gd = 1.0 / X_test.shape[1]\n",
    "param_grid = [{'C': [0.01, 0.1, 1.0, 10.0, 100.0], \n",
    "               'epsilon': [0.01, 0.1, 0.5, 1.0], \n",
    "               'gamma': [gd*10.0, gd, gd*0.1, gd*0.01]}]\n",
    "\n",
    "# Prep regressor\n",
    "svr = svm.SVR(kernel='rbf')\n",
    "\n",
    "# Run grid search\n",
    "clf = model_selection.GridSearchCV(svr, param_grid, \n",
    "                                   cv=cv_sets, scoring=scoring['explained_variance'],\n",
    "                                   n_jobs=6, verbose=2)\n",
    "clf.fit(fspace_TFOR_pca_rdy, rna_counts_rdy.ravel())\n",
    "\n",
    "# Report\n",
    "print \"Best estimator:\", clf.best_estimator_\n",
    "print \"Best score:\", clf.best_score_\n",
    "\n",
    "# Use best estimator for cross validation\n",
    "svr = clf.best_estimator_\n",
    "scores = model_selection.cross_validate(svr, fspace_TFOR_pca_rdy, rna_counts_rdy, \n",
    "                                        scoring=scoring, cv=cv_sets, \n",
    "                                        return_train_score=True, n_jobs=num_CVs)\n",
    "\n",
    "# Report CV scores\n",
    "print('\\nCV scores:')\n",
    "report_score(scores, 'train_explained_variance')\n",
    "report_score(scores, 'train_r2_score')\n",
    "report_score(scores, 'train_mean_squared_error')\n",
    "report_score(scores, 'test_explained_variance')\n",
    "report_score(scores, 'test_r2_score')\n",
    "report_score(scores, 'test_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Regression Plot\n",
    "\n",
    "# Single prediction\n",
    "svr.fit(X_train, y_train.ravel())\n",
    "y_train_pred = svr.predict(X_train)\n",
    "y_test_pred = svr.predict(X_test)\n",
    "\n",
    "# Prep plot\n",
    "fig, ax = plt.subplots(1, 2, figsize=(6,3), sharey=True)\n",
    "\n",
    "# Create plot\n",
    "ax[0].scatter(y_train, y_train_pred, color='cyan', edgecolor='darkcyan', alpha=0.5)\n",
    "ax[1].scatter(y_test, y_test_pred, color='cyan', edgecolor='darkcyan', alpha=0.5)\n",
    "\n",
    "# Reference line\n",
    "max_count = rna_counts_rdy.max()\n",
    "ax[0].plot([0,max_count], [0,max_count], '-', c='0.75', zorder=0)\n",
    "ax[1].plot([0,max_count], [0,max_count], '-', c='0.75', zorder=0)\n",
    "\n",
    "# Axis adjustments\n",
    "ax[0].set_xlim([0, max_count])\n",
    "ax[0].set_ylim([0, max_count])\n",
    "ax[1].set_xlim([0, max_count])\n",
    "ax[1].set_ylim([0, max_count])\n",
    "\n",
    "# Labeling\n",
    "ax[0].set_title('Training Data (TFOR)')\n",
    "ax[0].set_xlabel('Ground Truth')\n",
    "ax[0].set_ylabel('Predicted')\n",
    "ax[1].set_title('Test Data (TFOR)')\n",
    "ax[1].set_xlabel('Ground Truth')\n",
    "\n",
    "# Done\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting expression from CFOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare single train-test split for parametrization/visualization\n",
    "\n",
    "# Split\n",
    "out = model_selection.train_test_split(fspace_CFOR_pca_rdy, rna_counts_rdy, \n",
    "                                       test_size=test_size, random_state=42)\n",
    "X_train, X_test, y_train, y_test = out\n",
    "\n",
    "# Report\n",
    "print \"Final source fspace (full, train, test):\", fspace_CFOR_pca_rdy.shape, X_train.shape, X_test.shape\n",
    "print \"Final target fspace (full, train, test):\", rna_counts_rdy.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparam screening for SVR\n",
    "\n",
    "# Param grid\n",
    "gd = 1.0 / X_test.shape[1]\n",
    "param_grid = [{'C': [0.01, 0.1, 1.0, 10.0, 100.0], \n",
    "               'epsilon': [0.01, 0.1, 0.5, 1.0], \n",
    "               'gamma': [gd*10.0, gd, gd*0.1, gd*0.01]}]\n",
    "\n",
    "# Prep regressor\n",
    "svr = svm.SVR(kernel='rbf')\n",
    "\n",
    "# Run grid search\n",
    "clf = model_selection.GridSearchCV(svr, param_grid, \n",
    "                                   cv=cv_sets, scoring=scoring['explained_variance'],\n",
    "                                   n_jobs=6, verbose=2)\n",
    "clf.fit(fspace_CFOR_pca_rdy, rna_counts_rdy.ravel())\n",
    "\n",
    "# Report\n",
    "print \"Best estimator:\", clf.best_estimator_\n",
    "print \"Best score:\", clf.best_score_\n",
    "\n",
    "# Use best estimator for cross validation\n",
    "svr = clf.best_estimator_\n",
    "scores = model_selection.cross_validate(svr, fspace_CFOR_pca_rdy, rna_counts_rdy, \n",
    "                                        scoring=scoring, cv=cv_sets, \n",
    "                                        return_train_score=True, n_jobs=num_CVs)\n",
    "\n",
    "# Report CV scores\n",
    "print('\\nCV scores:')\n",
    "report_score(scores, 'train_explained_variance')\n",
    "report_score(scores, 'train_r2_score')\n",
    "report_score(scores, 'train_mean_squared_error')\n",
    "report_score(scores, 'test_explained_variance')\n",
    "report_score(scores, 'test_r2_score')\n",
    "report_score(scores, 'test_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Regression Plot\n",
    "\n",
    "# Single prediction\n",
    "svr.fit(X_train, y_train.ravel())\n",
    "y_train_pred = svr.predict(X_train)\n",
    "y_test_pred = svr.predict(X_test)\n",
    "\n",
    "# Prep plot\n",
    "fig, ax = plt.subplots(1, 2, figsize=(6,3), sharey=True)\n",
    "\n",
    "# Create plot\n",
    "ax[0].scatter(y_train, y_train_pred, color='cyan', edgecolor='darkcyan', alpha=0.5)\n",
    "ax[1].scatter(y_test, y_test_pred, color='cyan', edgecolor='darkcyan', alpha=0.5)\n",
    "\n",
    "# Reference line\n",
    "max_count = rna_counts_rdy.max()\n",
    "ax[0].plot([0,max_count], [0,max_count], '-', c='0.75', zorder=0)\n",
    "ax[1].plot([0,max_count], [0,max_count], '-', c='0.75', zorder=0)\n",
    "\n",
    "# Axis adjustments\n",
    "ax[0].set_xlim([0, max_count])\n",
    "ax[0].set_ylim([0, max_count])\n",
    "ax[1].set_xlim([0, max_count])\n",
    "ax[1].set_ylim([0, max_count])\n",
    "\n",
    "# Labeling\n",
    "ax[0].set_title('Training Data (CFOR)')\n",
    "ax[0].set_xlabel('Ground Truth')\n",
    "ax[0].set_ylabel('Predicted')\n",
    "ax[1].set_title('Test Data (CFOR)')\n",
    "ax[1].set_xlabel('Ground Truth')\n",
    "\n",
    "# Done\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting expression from position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare single train-test split for parametrization/visualization\n",
    "\n",
    "# Split\n",
    "out = model_selection.train_test_split(centroids_z_rdy, rna_counts_rdy,\n",
    "                                       test_size=test_size, random_state=42)\n",
    "X_train, X_test, y_train, y_test = out\n",
    "\n",
    "# Report\n",
    "print \"Final source fspace (full, train, test):\", centroids_z_rdy.shape, X_train.shape, X_test.shape\n",
    "print \"Final target fspace (full, train, test):\", rna_counts_rdy.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparam screening for SVR\n",
    "\n",
    "# Param grid\n",
    "gd = 1.0 / X_test.shape[1]\n",
    "param_grid = [{'C': [0.01, 0.1, 1.0, 10.0, 100.0], \n",
    "               'epsilon': [0.01, 0.1, 0.5, 1.0], \n",
    "               'gamma': [gd*10.0, gd, gd*0.1, gd*0.01]}]\n",
    "\n",
    "# Prep regressor\n",
    "svr = svm.SVR(kernel='rbf')\n",
    "\n",
    "# Run grid search\n",
    "clf = model_selection.GridSearchCV(svr, param_grid, \n",
    "                                   cv=cv_sets, scoring=scoring['explained_variance'],\n",
    "                                   n_jobs=6, verbose=2)\n",
    "clf.fit(centroids_z_rdy, rna_counts_rdy.ravel())\n",
    "        \n",
    "# Report\n",
    "print \"Best estimator:\", clf.best_estimator_\n",
    "print \"Best score:\", clf.best_score_\n",
    "\n",
    "# Use best estimator for cross validation\n",
    "svr = clf.best_estimator_\n",
    "scores = model_selection.cross_validate(svr, centroids_z_rdy, rna_counts_rdy, \n",
    "                                        scoring=scoring, cv=cv_sets, \n",
    "                                        return_train_score=True, n_jobs=num_CVs)\n",
    "\n",
    "# Report CV scores\n",
    "print('\\nCV scores:')\n",
    "report_score(scores, 'train_explained_variance')\n",
    "report_score(scores, 'train_r2_score')\n",
    "report_score(scores, 'train_mean_squared_error')\n",
    "report_score(scores, 'test_explained_variance')\n",
    "report_score(scores, 'test_r2_score')\n",
    "report_score(scores, 'test_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Regression Plot\n",
    "\n",
    "# Single prediction\n",
    "svr.fit(X_train, y_train.ravel())\n",
    "y_train_pred = svr.predict(X_train)\n",
    "y_test_pred = svr.predict(X_test)\n",
    "\n",
    "# Prep plot\n",
    "fig, ax = plt.subplots(1, 2, figsize=(6,3), sharey=True)\n",
    "\n",
    "# Create plot\n",
    "ax[0].scatter(y_train, y_train_pred, color='cyan', edgecolor='darkcyan', alpha=0.5)\n",
    "ax[1].scatter(y_test, y_test_pred, color='cyan', edgecolor='darkcyan', alpha=0.5)\n",
    "\n",
    "# Reference line\n",
    "max_count = rna_counts_rdy.max()\n",
    "ax[0].plot([0,max_count], [0,max_count], '-', c='0.75', zorder=0)\n",
    "ax[1].plot([0,max_count], [0,max_count], '-', c='0.75', zorder=0)\n",
    "\n",
    "# Axis adjustments\n",
    "ax[0].set_xlim([0, max_count])\n",
    "ax[0].set_ylim([0, max_count])\n",
    "ax[1].set_xlim([0, max_count])\n",
    "ax[1].set_ylim([0, max_count])\n",
    "\n",
    "# Labeling\n",
    "ax[0].set_title('Training Data (Location)')\n",
    "ax[0].set_xlabel('Ground Truth')\n",
    "ax[0].set_ylabel('Predicted')\n",
    "ax[1].set_title('Test Data (Location)')\n",
    "ax[1].set_xlabel('Ground Truth')\n",
    "\n",
    "# Done\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting expression from TFOR+CFOR+position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prep combined data data\n",
    "\n",
    "# Combine\n",
    "fspace_combined = np.concatenate([fspace_TFOR_pca_rdy, fspace_CFOR_pca_rdy, centroids_z_rdy], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare single train-test split for parametrization/visualization\n",
    "\n",
    "# Split\n",
    "out = model_selection.train_test_split(fspace_combined, rna_counts_rdy,\n",
    "                                       test_size=test_size, random_state=42)\n",
    "X_train, X_test, y_train, y_test = out\n",
    "\n",
    "# Report\n",
    "print \"Final source fspace (full, train, test):\", fspace_combined.shape, X_train.shape, X_test.shape\n",
    "print \"Final target fspace (full, train, test):\", rna_counts_rdy.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparam screening for SVR\n",
    "\n",
    "# Param grid\n",
    "gd = 1.0 / X_test.shape[1]\n",
    "param_grid = [{'C': [0.01, 0.1, 1.0, 10.0, 100.0], \n",
    "               'epsilon': [0.01, 0.1, 0.5, 1.0], \n",
    "               'gamma': [gd*10.0, gd, gd*0.1, gd*0.01]}]\n",
    "\n",
    "# Prep regressor\n",
    "svr = svm.SVR(kernel='rbf')\n",
    "\n",
    "# Run grid search\n",
    "clf = model_selection.GridSearchCV(svr, param_grid, \n",
    "                                   cv=cv_sets, scoring=scoring['explained_variance'],\n",
    "                                   n_jobs=6, verbose=2)\n",
    "clf.fit(fspace_combined, rna_counts_rdy.ravel())\n",
    "        \n",
    "# Report\n",
    "print \"Best estimator:\", clf.best_estimator_\n",
    "print \"Best score:\", clf.best_score_\n",
    "\n",
    "# Use best estimator for cross validation\n",
    "svr = clf.best_estimator_\n",
    "scores = model_selection.cross_validate(svr, fspace_combined, rna_counts_rdy, \n",
    "                                        scoring=scoring, cv=cv_sets, \n",
    "                                        return_train_score=True, n_jobs=num_CVs)\n",
    "\n",
    "# Report CV scores\n",
    "print('\\nCV scores:')\n",
    "report_score(scores, 'train_explained_variance')\n",
    "report_score(scores, 'train_r2_score')\n",
    "report_score(scores, 'train_mean_squared_error')\n",
    "report_score(scores, 'test_explained_variance')\n",
    "report_score(scores, 'test_r2_score')\n",
    "report_score(scores, 'test_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Regression Plot\n",
    "\n",
    "# Single prediction\n",
    "svr.fit(X_train, y_train.ravel())\n",
    "y_train_pred = svr.predict(X_train)\n",
    "y_test_pred = svr.predict(X_test)\n",
    "\n",
    "# Prep plot\n",
    "fig, ax = plt.subplots(1, 2, figsize=(6,3), sharey=True)\n",
    "\n",
    "# Create plot\n",
    "ax[0].scatter(y_train, y_train_pred, color='cyan', edgecolor='darkcyan', alpha=0.5)\n",
    "ax[1].scatter(y_test, y_test_pred, color='cyan', edgecolor='darkcyan', alpha=0.5)\n",
    "\n",
    "# Reference line\n",
    "max_count = rna_counts_rdy.max()\n",
    "ax[0].plot([0,max_count], [0,max_count], '-', c='0.75', zorder=0)\n",
    "ax[1].plot([0,max_count], [0,max_count], '-', c='0.75', zorder=0)\n",
    "\n",
    "# Axis adjustments\n",
    "ax[0].set_xlim([0, max_count])\n",
    "ax[0].set_ylim([0, max_count])\n",
    "ax[1].set_xlim([0, max_count])\n",
    "ax[1].set_ylim([0, max_count])\n",
    "\n",
    "# Labeling\n",
    "ax[0].set_title('Training Data (COMBINED)')\n",
    "ax[0].set_xlabel('Ground Truth')\n",
    "ax[0].set_ylabel('Predicted')\n",
    "ax[1].set_title('Test Data (COMBINED)')\n",
    "ax[1].set_xlabel('Ground Truth')\n",
    "\n",
    "# Done\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretty regression plot for publication\n",
    "\n",
    "# Single prediction\n",
    "svr.fit(X_train, y_train.ravel())\n",
    "y_train_pred = svr.predict(X_train)\n",
    "y_test_pred = svr.predict(X_test)\n",
    "\n",
    "# Prep plot\n",
    "fig, ax = plt.subplots(1, 2, figsize=(6, 3.2), sharey=True)\n",
    "\n",
    "# Create plot\n",
    "ax[0].scatter(y_train, y_train_pred, \n",
    "              color='midnightblue', edgecolor='', alpha=0.3, s=5)\n",
    "ax[1].scatter(y_test, y_test_pred, \n",
    "              color='midnightblue', edgecolor='', alpha=0.3, s=5)\n",
    "\n",
    "# Reference line\n",
    "max_count = rna_counts_rdy.max()\n",
    "ax[0].plot([0,max_count], [0,max_count], '-', c='0.75', zorder=0)\n",
    "ax[1].plot([0,max_count], [0,max_count], '-', c='0.75', zorder=0)\n",
    "\n",
    "# Crop off and add cropped points back as arrows\n",
    "crop = 60\n",
    "if np.any(y_train_pred>crop) or np.any(y_test_pred>crop):\n",
    "    raise ValueError('Some predicted values are higher than `crop`!')\n",
    "ax[0].scatter([crop-0.5 for i in range(np.sum(y_train[:,0]>60))], y_train_pred[y_train[:,0]>60],\n",
    "              color='midnightblue', edgecolor='', alpha=0.5, s=10, marker='>')\n",
    "ax[1].scatter([crop-0.5 for i in range(np.sum(y_test[:,0]>60))], y_test_pred[y_test[:,0]>60],\n",
    "              color='midnightblue', edgecolor='', alpha=0.5, s=10, marker='>')\n",
    "\n",
    "# Axis adjustments\n",
    "ax[0].set_xlim([0, crop])\n",
    "ax[0].set_ylim([0, crop])\n",
    "ax[1].set_xlim([0, crop])\n",
    "ax[1].set_ylim([0, crop])\n",
    "\n",
    "# Axis cosmetics\n",
    "ax[0].yaxis.set_ticks_position('left')\n",
    "ax[0].xaxis.set_ticks_position('bottom')\n",
    "ax[1].yaxis.set_ticks_position('left')\n",
    "ax[1].xaxis.set_ticks_position('bottom')\n",
    "\n",
    "# Labeling & other cosmetics\n",
    "ax[0].set_title('Training Data')\n",
    "ax[0].set_xlabel('$\\it{pea3}$ counts (ground truth)')\n",
    "ax[0].set_ylabel('$\\it{pea3}$ counts (predicted)')\n",
    "ax[1].set_title('Test Data')\n",
    "ax[1].set_xlabel('$\\it{pea3}$ counts (ground truth)')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Done\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=atlas_run></a>\n",
    "\n",
    "## 6. Predicting Expression from Shape: Running\n",
    "[back to top](#top)\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load and prepare full live-imaged shape space\n",
    "\n",
    "# Prep loader\n",
    "expA_loader = ld.DataLoaderIDR()\n",
    "expA_loader.find_imports(r\"data/experimentA/extracted_measurements/\", recurse=True, verbose=True)\n",
    "\n",
    "# Import shape spaces\n",
    "expA_TFOR_pca, expA_IDs, expA_idx = expA_loader.load_dataset(\"shape_TFOR_pca_measured.tsv\")\n",
    "expA_CFOR_pca, _, _ = expA_loader.load_dataset(\"shape_CFOR_pca_measured.tsv\", IDs=expA_IDs)\n",
    "print \"Imported TFOR shape space of shape:\", expA_TFOR_pca.shape\n",
    "print \"Imported CFOR shape space of shape:\", expA_CFOR_pca.shape\n",
    "\n",
    "# Import TFOR centroid locations\n",
    "expA_centroids = expA_loader.load_dataset(\"_other_measurements.tsv\", IDs=expA_IDs)[0][:,3:6][:,::-1]\n",
    "print \"Imported TFOR centroids of shape:\", expA_centroids.shape\n",
    "expA_centroids_z = StandardScaler().fit_transform(expA_centroids)\n",
    "\n",
    "# Combine\n",
    "expA_combined = np.concatenate([expA_TFOR_pca[:,:use_PCs], expA_CFOR_pca[:,:use_PCs], expA_centroids_z], axis=1)\n",
    "\n",
    "# Report\n",
    "print expA_TFOR_pca.shape, expA_CFOR_pca.shape, expA_centroids_z.shape, expA_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run best possible smFISH count prediction for entire atlas\n",
    "\n",
    "# Prepare the best regressor \n",
    "svr = svm.SVR(kernel='rbf', C=10.0, epsilon=0.01, gamma = 1.0 / X_test.shape[1] * 0.1)\n",
    "\n",
    "# Train based on entire smFISH dataset\n",
    "svr.fit(fspace_combined, rna_counts_rdy.ravel())\n",
    "\n",
    "# Predict for entire atlas\n",
    "expA_counts = svr.predict(expA_combined)\n",
    "\n",
    "# Set the occasional negative count to zero\n",
    "expA_counts[expA_counts < 0.0] = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=atlas_viz></a>\n",
    "\n",
    "## 7. Predicting Expression from Shape: Visualization\n",
    "[back to top](#top)\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### QC: Compare predicted atlas counts to measured counts\n",
    "\n",
    "# Note:\n",
    "#  This looks quite good. The prediction obviously doesn't capture the long \n",
    "#  tail of the real measurements, which also pulls the overall average down\n",
    "#  a bit. This was to be expected and may not even be wrong.\n",
    "\n",
    "# Get count means\n",
    "count_means = np.array([np.mean(rna_counts[fspace_idx==prim_idx]) \n",
    "                        for prim_idx in range(len(prim_IDs))])\n",
    "expA_means = np.array([np.mean(expA_counts[expA_idx==prim_idx]) \n",
    "                        for prim_idx in range(len(expA_IDs))])\n",
    "\n",
    "# Fig prep\n",
    "fig, ax = plt.subplots(1, 2, figsize=(6, 4.5), sharey=True)\n",
    "\n",
    "# Make boxplots\n",
    "bp_m = ax[0].boxplot([count_means, expA_means], widths=0.65, patch_artist=True, showfliers=False)\n",
    "bp_a = ax[1].boxplot([rna_counts, expA_counts], widths=0.65, patch_artist=True, showfliers=False)\n",
    "\n",
    "# Boxplot styling function (making it similar to Sevi's paper)\n",
    "def style_boxplot(bp):\n",
    "    for patch in bp['boxes']:\n",
    "        patch.set(edgecolor='black', linewidth=1.2,)\n",
    "    for whisker in bp['whiskers']:\n",
    "        whisker.set(color='black', linestyle='-')\n",
    "    for cap in bp['caps']:\n",
    "        cap.set(linewidth=1.2)\n",
    "    for median in bp['medians']:\n",
    "        median.set(color='black', linewidth=1.2)\n",
    "        \n",
    "# Style the boxplots\n",
    "style_boxplot(bp_m)\n",
    "style_boxplot(bp_a)\n",
    "\n",
    "# Add scatter\n",
    "ax[0].scatter(np.random.normal(1.0, 0.06, len(count_means)), count_means, \n",
    "              zorder=10, s=20, alpha=0.7, c='midnightblue', edgecolor='')\n",
    "ax[0].scatter(np.random.normal(2.0, 0.08, len(expA_means)), expA_means, \n",
    "              zorder=10, s=20, alpha=0.3, c='purple', edgecolor='')\n",
    "ax[1].scatter(np.random.normal(1.0, 0.06, len(rna_counts)), rna_counts, \n",
    "              zorder=10, s=2, alpha=0.2, c='midnightblue', edgecolor='')\n",
    "ax[1].scatter(np.random.normal(2.0, 0.10, len(expA_counts)), expA_counts, \n",
    "              zorder=10, s=2, alpha=0.05, c='purple', edgecolor='')\n",
    "\n",
    "# Add arrows for outliers\n",
    "crop = 50\n",
    "ax[1].scatter(np.random.normal(1.0, 0.06, np.sum(rna_counts>crop)), \n",
    "              [crop-0.5 for i in range(np.sum(rna_counts>crop))],\n",
    "              color='midnightblue', edgecolor='', alpha=0.2, s=10, marker='^')\n",
    "if np.any(expA_counts > crop): raise ValueError()\n",
    "\n",
    "# Set axis limits\n",
    "ax[0].set_ylim([-2, crop])\n",
    "\n",
    "# Remove axis ticks\n",
    "ax[0].yaxis.set_ticks_position('left')\n",
    "ax[0].xaxis.set_ticks_position('bottom')\n",
    "ax[1].yaxis.set_ticks_position('left')\n",
    "ax[1].xaxis.set_ticks_position('bottom')\n",
    "\n",
    "# Axis labels\n",
    "from matplotlib import rcParams\n",
    "rcParams['mathtext.default'] = 'regular'\n",
    "ax[0].set_ylabel(r'$\\it{pea3}$ transcripts per cell', fontsize=16, labelpad=5)\n",
    "ax[0].set_title('sample means', fontsize=16)\n",
    "ax[1].set_title('all cells', fontsize=16)\n",
    "ax[0].set_xticklabels(['smFISH', 'atlas'], fontsize=14)\n",
    "ax[1].set_xticklabels(['smFISH', 'atlas'], fontsize=14)\n",
    "ax[0].tick_params(axis='y', which='major', labelsize=14)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Print stats\n",
    "print 'pMWU(means):', stats.mannwhitneyu(count_means, expA_means, alternative='two-sided')[1]\n",
    "print 'pMWU(all):', stats.mannwhitneyu(rna_counts, expA_counts, alternative='two-sided')[1]\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Atlas tissue consensus map\n",
    "\n",
    "# Settings\n",
    "xlim = (-130,  8)\n",
    "ylim = ( -19, 19)\n",
    "\n",
    "# Get plot values & remove outliers\n",
    "plot_values = expA_counts\n",
    "\n",
    "# Tools for smoothing on scatter\n",
    "from katachi.utilities.pcl_helpers import pcl_gaussian_smooth\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# Cut off at prim contour outline\n",
    "kernel_prim = stats.gaussian_kde(expA_centroids[:,1:].T)\n",
    "f_prim = kernel_prim(expA_centroids[:,1:].T)\n",
    "f_prim_mask = f_prim > f_prim.min() + (f_prim.max()-f_prim.min())*0.1\n",
    "plot_values = plot_values[f_prim_mask]\n",
    "plot_centroids = expA_centroids[f_prim_mask]\n",
    "\n",
    "# Smoothen?\n",
    "pdists = squareform(pdist(plot_centroids[:,1:]))\n",
    "plot_values = pcl_gaussian_smooth(pdists, plot_values[:,np.newaxis], sg_percentile=0.5)[:,0]\n",
    "\n",
    "# Initialize figure\n",
    "fig, ax = plt.subplots(1, figsize=(8, 2.8))\n",
    "\n",
    "# Contourf plot\n",
    "cfset = ax.tricontourf(plot_centroids[:,2], plot_centroids[:,1], plot_values, 20, \n",
    "                       cmap='plasma', vmax=20)  # NOTE: vmax set to be consistent with measured plot!\n",
    "\n",
    "# Illustrative centroids from a single prim\n",
    "plt.scatter(expA_centroids[expA_idx==expA_IDs.index(expA_IDs[0]), 2], \n",
    "            expA_centroids[expA_idx==expA_IDs.index(expA_IDs[0]), 1],\n",
    "            c='', alpha=0.5)\n",
    "\n",
    "# Cosmetics\n",
    "ax.set_xlabel('TFOR x', fontsize=16)\n",
    "ax.set_ylabel('TFOR y', fontsize=16)\n",
    "plt.tick_params(axis='both', which='major', labelsize=13)\n",
    "plt.xlim(xlim); plt.ylim(ylim)\n",
    "ax.invert_yaxis()  # To match images\n",
    "\n",
    "# Colorbar\n",
    "cbar = plt.colorbar(cfset, ax=ax, pad=0.01)\n",
    "cbar.set_label('RNA Counts', rotation=270, labelpad=15, fontsize=16)\n",
    "cbar.ax.tick_params(labelsize=13)\n",
    "\n",
    "# Finalize\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "[back to top](#top)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "state": {
    "3ba59fcd12c44edcadc32bac6ae60a05": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "6470c7e08f514202a1e57e69fd4e03e3": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "97b5c8d887e64ad5b7096b445627d31c": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "9aacb52c19c547fcb365b6b3d8b84ca8": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "c20f9e5baf5942bda5cb79c22b7f8ce2": {
     "views": [
      {
       "cell_index": 40
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
