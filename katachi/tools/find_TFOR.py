# -*- coding: utf-8 -*-
"""
Created on Sun Dec 03 15:55:54 2017

@author:    Jonas Hartmann @ Gilmour group @ EMBL Heidelberg

@descript:  Transform a set of cell point clouds to a common frame of reference
            based on tissue orientation ("Tissue Frame Of Reference" or TFOR),
            in this specific case the "Primordium Frame Of Reference" (PFOR).
"""

#------------------------------------------------------------------------------

# IMPORTS

# External
from __future__ import division
import os, pickle
import numpy as np
from tifffile import imread
from sklearn.decomposition import PCA

# Internal
from katachi.utilities.ISLA import isla
from katachi.utilities.plotting import point_cloud_3D


#------------------------------------------------------------------------------

# FUNCTION: TRANSFORM CELL POINT CLOUDS TO PRIM FRAME OF REFERENCE

def transform_to_TFOR(fpath_seg, fpaths_lm,
                      n_points=3000,
                      verbose=False, show=False):
    """Transform a prim's cellular point clouds to the corresponding tissue
    frame of reference (TFOR), i.e. the primordium frame of reference (PFOR).

    For downstream processing, cellular point clouds must be brought to a
    common frame of reference. In the case of the lateral line primordium, one
    such frame of reference is that of the tissue as a whole.

    This function determines how a given primordium would have to be trans-
    formed to align it with the image axes. By doing this, different prims are
    automatically registered (without a "registration proper"). The function
    then transforms the given prim's cellular point cloud accordingly, thus
    bringing them into a common "tissue frame of reference" with any other cell
    point cloud that has been transformed in the same way.

    The transformation is detected by performing a PCA, which will detect the
    major axes of the primordium. PCs are flipped to align positively with the
    corresponding image axis and sorted to be in the same order as the image
    dimensions. Cell point clouds are then transformed by the same PCA.

    The origin of the frame of reference is left untouched in y and z (after
    the PCA it will be in the center of the tissue) and is set to the very tip
    of the segmentation mask in x (registration to the tip of the prim).

    In addition to saving the transformed landmarks, the function writes the
    transformed centroids, the PCA object itself and the origin and transformed
    origin to the stack metadata.

    WARNING: The approach used here has been developed for the Zebrafish
    posterior lateral line primordium. It is likely not readily applicable to
    other tissues!

    Parameters
    ----------
    fpath_seg : string
        The path (either local from cwd or global) to a tif file containing
        the single-cell segmentation stack. The total masked volume (all cells)
        is used for determining the frame of reference.
    fpaths_lm : list or string
        A path or list of paths (either local from cwd or global) to npy files
        containing cellular landmarks as generated by
        `katachi.tools.assign_landmarks`.
    n_points : int, optional, Default 3000
        The number of landmarks extracted from the overall segmentation mask.
        These landmarks are used to determine the transform.
    verbose : bool, optional, default False
        If True, more information is printed.
    show : bool, optional, default False
        If True, 3D plots of the PCA transform and the origin are produced.
    """

    #--------------------------------------------------------------------------

    ### Load data

    if verbose: print "Loading data..."

    # Try loading the segmentation stack
    try:
        img_seg = imread(fpath_seg)
    except:
        print "Attempting to load segmentation stack failed with this error:"
        raise

    # Check dimensionality
    if not img_seg.ndim == 3:
        raise IOError("Expected a 3D segmentation stack, got " +
                      str(img_seg.ndim) + "D instead.")

    # Try loading the landmark data
    if type(fpaths_lm) == str:
        fpaths_lm = [fpaths_lm]
    lm_data = {}
    for fpath_lm in fpaths_lm:
        try:
            lm_data[fpath_lm] = np.load(fpath_lm)
        except:
            print "Attempting to load landmark data failed with this error:"
            raise

    # Try loading centroid data and resolution information
    try:
        dirpath, fname = os.path.split(fpath_seg)
        fpath_meta = os.path.join(dirpath, fname[:10]+"_stack_metadata.pkl")
        with open(fpath_meta, 'rb') as metafile:
            meta_dict = pickle.load(metafile)
        centroids = meta_dict["centroids"]
        res = meta_dict["resolution"]
    except:
        print "Getting centroid positions / resolution failed with this error:"
        raise


    #--------------------------------------------------------------------------

    ### Create point cloud of tissue mask using ISLA

    if verbose: print "Creating tissue point cloud..."

    # Run ISLA
    cloud = isla(img_seg > 0, n_points, seed=42)

    # Change from pixels to um
    cloud = cloud * np.array(res)


    #--------------------------------------------------------------------------

    ### Find and transform to a common frame of reference
    #   Note: Here, this is done by finding the major axes of the point cloud
    #         by PCA and then transforming them so they are aligned with the
    #         axes of the microscopy image. In this way, all prims will end up
    #         in the same FOR without the need for a proper registration.

    if verbose: print "Finding common frame of reference..."

    # Fit PCA model to data
    pca = PCA()
    pca.fit(cloud)

    # Ensure that the sign of PCs is consistent with the image orientation
    # Note: Given that the images are always acquired in the same orientations,
    #       a matching orientation can be ensured by finding the highest
    #       contributing image axis for each PC, and invert the PC if that
    #       contribution is negative. In other words, ensuring for each PC that
    #       it is positively correlated with the corresponding image axis.

    # Find highest contributions of image axes to each PC
    # Note: This asks "which image axis contributes the most to each PC?"
    max_weights = np.argmax(np.abs(pca.components_), axis=1)

    # Get the signs of the highest contributions
    signs = np.sign( pca.components_[np.arange(pca.components_.shape[0]),
                                     max_weights] )

    # Using the signs, flip those PCs where the sign is negative
    pca.components_ = pca.components_ * signs[:, np.newaxis]

    # Match the order of PCs to the order of image dimensions (zyx)
    # Note: Following the transform, the PCs will be sorted according to
    #       explained variance. Instead, they should be sorted in order of the
    #       highest contributing image dimension.

    # Find indices for zyx-sorting of transformed data
    # Note: This asks "which PC is most contributed to by each image axis?"
    zyx_sort = np.argmax(np.abs(pca.components_), axis=0)

    # If the image is not a proper prim where (with extents x>y>z),
    # this sort may fail terminally; if so, abort!
    if not np.all(np.sort(zyx_sort) == np.array([0,1,2])):
        raise Exception("Primordium mask extents are not x>y>z in "+fpath_seg)

    # Transform cloud to PFOR with matching signs and sort to zyx order
    cloud_tf = pca.transform(cloud)[:,zyx_sort]

    # Get PCs and explained variance for visualization
    # Note: np.copy may not be necessary but I want to be careful about the
    #       mutability of pca's attributes...
    PCs = np.copy(pca.components_.T)
    PCvars = np.copy(pca.explained_variance_ratio_)

    # Print results
    if verbose:
        print '  PCs:'
        print '   ', str(PCs).replace('\n','\n    ')
        print '  Explained variance:'
        print '   ', str(PCvars)

    # Plot the outcome
    if show:

        # Prepare PC axis dots
        extents = [np.min(cloud_tf, axis=0), np.max(cloud_tf, axis=0)]
        pcax_tf = np.zeros((300,3))
        for d in range(3):
            pcax_tf[d*100:(d+1)*100,d] = np.linspace(extents[0][d],
                                                     extents[1][d], num=100)
        pcax = pca.inverse_transform(pcax_tf[:,np.argsort(zyx_sort)])

        # Plot stuff (before transform)
        fig, ax = point_cloud_3D(cloud[:,2], cloud[:,1], cloud[:,0],
                                 fin=False, title="Before Transform",
                                 xlbl='x', ylbl='y', zlbl='z')
        point_cloud_3D(pcax[:,2], pcax[:,1], pcax[:,0],
                       c='r', init=False, pre_fig=fig, pre_ax=ax)

        # After transform
        fig, ax = point_cloud_3D(cloud_tf[:,2], cloud_tf[:,1], cloud_tf[:,0],
                                 fin=False, title="After Transform",
                                 xlbl='x', ylbl='y', zlbl='z')
        point_cloud_3D(pcax_tf[:,2], pcax_tf[:,1], pcax_tf[:,0],
                       c='r', init=False, pre_fig=fig, pre_ax=ax)


    #--------------------------------------------------------------------------

    ### Find the proper origin
    # Note: In transformed space, y and z are already nicely centered so they
    #       can be used for the origin directly (i.e. one can just use 0). For
    #       x, the tip position is used as it is the most straightforwardly
    #       extractable common reference point. Note that the tip position is
    #       measured from the segmentation, not from the point cloud.

    # Initialize the origin point
    origin_tf = np.zeros(3)

    # Find tip (in real space), transform it, add x component to origin
    ind   = np.where(img_seg > 0) # Indices of the mask
    tip_x = np.max(ind[2])        # Index of greatest x (tip)
    tip_point = np.array((ind[0][tip_x], ind[1][tip_x], tip_x)) # Tip in 3D
    tip_point = tip_point * np.array(res)                       # In microns
    transf_tip_point = pca.transform(tip_point.reshape((1,3)))[0,zyx_sort] # tf
    origin_tf[2] = transf_tip_point[2] # Assign x component as origin

    # Inverse transform to get origin in imaging space
    # (including the x and y components, which are 0 in PFOR)
    origin = pca.inverse_transform(origin_tf[np.argsort(zyx_sort)])

    # Show the origin
    if show:
        fig, ax = point_cloud_3D(origin[2], origin[1], origin[0],
                       c='r', s=200, fin=False, config=False)
        point_cloud_3D(cloud[:,2], cloud[:,1], cloud[:,0],
                       init=False, pre_fig=fig, pre_ax=ax,
                       title="Origin Point", xlbl='x', ylbl='y', zlbl='z')


    #--------------------------------------------------------------------------

    ### Transform data so origin lies at (0,0,0)

    # Transformation
    cloud_tf = cloud_tf - origin_tf


    #--------------------------------------------------------------------------

    ### Transform the cell point clouds to the PFOR

    if verbose: print "Transforming cells to common frame of reference..."

    # First, also transform the centroids to the PFOR
    centroids_tf = pca.transform(centroids)[:,zyx_sort] - origin_tf

    # For each landmark dataset...
    lm_data_tf = {}
    for key in lm_data.keys():

        # For each cell...
        cell_tf = np.zeros_like(lm_data[key])
        for i in range(cell_tf.shape[0]):

            # Translate the point cloud to the position in the image FOR
            cell_cloud = lm_data[key][i,:,:] + centroids[i]

            # Transform the cell cloud to PFOR
            cell_cloud = pca.transform(cell_cloud)[:,zyx_sort] - origin_tf

            # Set the cloud's origin to the PFOR centroid
            cell_tf[i,:,:] = cell_cloud - centroids_tf[i]

        # Add to the new data dict
        lm_data_tf[key] = cell_tf


    #--------------------------------------------------------------------------

    ### Write results

    if verbose: print "Saving results..."

    # Write the transformed landmark point clouds
    for key in lm_data_tf.keys():
        np.save(key[:-4]+"_TFOR", lm_data_tf[key])

    # Write origins, the PCA object and the transformed centroids to metadata
    meta_dict["origin"]         = origin
    meta_dict["originTFOR"]    = origin_tf
    meta_dict["TFOR_PCA"]       = pca
    meta_dict["centroids_TFOR"] = centroids_tf
    with open(fpath_meta, 'wb') as metafile:
        pickle.dump(meta_dict, metafile, pickle.HIGHEST_PROTOCOL)

    # Report and return
    if verbose: print "Processing complete!"
    return


#------------------------------------------------------------------------------



